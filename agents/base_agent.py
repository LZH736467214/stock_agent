"""
AgentåŸºç±»
æä¾›ReAct Agentçš„åŸºç¡€å®ç°
"""
from abc import ABC, abstractmethod
from typing import List, Any, Optional
from langchain_core.tools import BaseTool
from langchain_core.callbacks import BaseCallbackHandler
from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent
import sys
import time
sys.path.insert(0, str(__file__).rsplit('\\', 2)[0])
from config import config


class LLMProgressCallback(BaseCallbackHandler):
    """LLMå’Œå·¥å…·è°ƒç”¨è¿›åº¦å›è°ƒï¼Œæ˜¾ç¤ºæ‰§è¡Œè¿‡ç¨‹çš„æç¤º"""
    
    def __init__(self, agent_name: str = "Agent"):
        self.agent_name = agent_name
        self.llm_call_count = 0
        self.tool_call_count = 0
    
    def on_llm_start(self, serialized, prompts, **kwargs):
        """LLMå¼€å§‹è°ƒç”¨æ—¶è§¦å‘"""
        self.llm_call_count += 1
        current_time = time.strftime("%H:%M:%S")
        print(f"    ğŸ’­ [{current_time}] [{self.agent_name}] æ­£åœ¨è°ƒç”¨LLMåˆ†æ (ç¬¬{self.llm_call_count}æ¬¡)...", flush=True)
    
    def on_llm_end(self, response, **kwargs):
        """LLMè°ƒç”¨ç»“æŸæ—¶è§¦å‘"""
        current_time = time.strftime("%H:%M:%S")
        print(f"    âœ“  [{current_time}] [{self.agent_name}] LLMå“åº”å®Œæˆ", flush=True)
    
    def on_tool_start(self, serialized, input_str, **kwargs):
        """å·¥å…·å¼€å§‹è°ƒç”¨æ—¶è§¦å‘"""
        self.tool_call_count += 1
        tool_name = serialized.get("name", "æœªçŸ¥å·¥å…·")
        current_time = time.strftime("%H:%M:%S")
        print(f"    ğŸ”§ [{current_time}] [{self.agent_name}] æ­£åœ¨è°ƒç”¨å·¥å…·: {tool_name}...", flush=True)
    
    def on_tool_end(self, output, **kwargs):
        """å·¥å…·è°ƒç”¨ç»“æŸæ—¶è§¦å‘"""
        current_time = time.strftime("%H:%M:%S")
        output_len = len(str(output)) if output else 0
        print(f"    âœ“  [{current_time}] [{self.agent_name}] å·¥å…·è¿”å›: {output_len} å­—ç¬¦", flush=True)


class BaseAgent(ABC):
    """AgentåŸºç±»"""
    
    def __init__(
        self,
        name: str,
        tools: List[BaseTool],
        system_prompt: str,
        model: Optional[str] = None
    ):
        """
        åˆå§‹åŒ–Agent
        
        Args:
            name: Agentåç§°
            tools: å¯ç”¨å·¥å…·åˆ—è¡¨
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
        """
        self.name = name
        self.tools = tools
        self.system_prompt = system_prompt
        self.model = model or config.OPENAI_MODEL
        
        # åˆ›å»ºè¿›åº¦å›è°ƒ
        self.progress_callback = LLMProgressCallback(agent_name=name)
        
        # åˆ›å»ºLLM (æ·»åŠ è¶…æ—¶é…ç½®å’Œè¿›åº¦å›è°ƒ)
        self.llm = ChatOpenAI(
            api_key=config.OPENAI_API_KEY,
            base_url=config.OPENAI_BASE_URL,
            model=self.model,
            temperature=0,
            request_timeout=60,  # 60ç§’è¶…æ—¶
            callbacks=[self.progress_callback],  # æ·»åŠ LLMè°ƒç”¨è¿›åº¦å›è°ƒ
        )
        
        # åˆ›å»ºReAct Agent (å¦‚æœæœ‰å·¥å…·)
        if tools:
            self.agent = create_react_agent(
                model=self.llm,
                tools=tools,
                # å…¼å®¹æ€§ä¿®å¤ï¼šç§»é™¤modifierå‚æ•°ï¼Œæ”¹ç”¨SystemMessage
                # state_modifier=system_prompt  <- æ—§ç‰ˆæœ¬
                # messages_modifier=system_prompt <- æ–°ç‰ˆæœ¬
            )
            # è®¾ç½®é€’å½’é™åˆ¶ (é˜²æ­¢æ— é™å¾ªç¯)
            self.recursion_limit = 25  # æœ€å¤š25æ¬¡å·¥å…·è°ƒç”¨
        else:
            self.agent = None
            self.recursion_limit = 10
    
    def invoke(self, input_data: dict, debug: bool = False) -> dict:
        """
        æ‰§è¡ŒAgent
        
        Args:
            input_data: è¾“å…¥æ•°æ®
            debug: æ˜¯å¦å¼€å¯è°ƒè¯•æ¨¡å¼ (æ˜¾ç¤ºè¯¦ç»†æ‰§è¡Œè¿‡ç¨‹)
        
        Returns:
            æ‰§è¡Œç»“æœ
        """
        if self.agent:
            # æ‰‹åŠ¨æ·»åŠ SystemMessageä»¥å…¼å®¹ä¸åŒç‰ˆæœ¬
            from langchain_core.messages import SystemMessage
            import time
            
            messages = input_data.get("messages", [])
            # ç¡®ä¿system_promptä½œä¸ºç¬¬ä¸€æ¡æ¶ˆæ¯
            if self.system_prompt:
                system_msg = SystemMessage(content=self.system_prompt)
                # æ£€æŸ¥æ˜¯å¦å·²æœ‰SystemMessage
                if not messages or not isinstance(messages[0], SystemMessage):
                    messages = [system_msg] + messages
                
            # ä½¿ç”¨ReAct Agent (å¸¦é€’å½’é™åˆ¶)
            input_data["messages"] = messages
            config_dict = {"recursion_limit": self.recursion_limit}
            
            if debug:
                # è°ƒè¯•æ¨¡å¼ï¼šä½¿ç”¨ stream æ˜¾ç¤ºæ¯ä¸€æ­¥
                print(f"\n    [DEBUG] å¼€å§‹æ‰§è¡Œ {self.name}")
                print(f"    [DEBUG] é€’å½’é™åˆ¶: {self.recursion_limit}")
                step_count = 0
                result = None
                
                for event in self.agent.stream(input_data, config=config_dict):
                    step_count += 1
                    current_time = time.strftime("%H:%M:%S")
                    
                    for key, value in event.items():
                        print(f"    [{current_time}] Step {step_count}: {key}")
                        
                        if key == "agent":
                            # LLM å“åº”
                            if "messages" in value:
                                for msg in value["messages"]:
                                    msg_type = type(msg).__name__
                                    if hasattr(msg, 'tool_calls') and msg.tool_calls:
                                        tool_names = [tc['name'] for tc in msg.tool_calls]
                                        print(f"        â†’ LLM å†³ç­–: è°ƒç”¨å·¥å…· {tool_names}")
                                    elif hasattr(msg, 'content') and msg.content:
                                        content_preview = msg.content[:100].replace('\n', ' ')
                                        print(f"        â†’ LLM å“åº”: {content_preview}...")
                        
                        elif key == "tools":
                            # å·¥å…·è°ƒç”¨ç»“æœ
                            if "messages" in value:
                                for msg in value["messages"]:
                                    if hasattr(msg, 'name'):
                                        content_len = len(msg.content) if hasattr(msg, 'content') else 0
                                        print(f"        â†’ å·¥å…· {msg.name} è¿”å›: {content_len} å­—ç¬¦")
                        
                        result = value
                
                print(f"    [DEBUG] æ‰§è¡Œå®Œæˆï¼Œå…± {step_count} æ­¥")
                return result if result else {"messages": messages}
            else:
                # æ­£å¸¸æ¨¡å¼ - ä¼ é€’ callbacks ä»¥æ˜¾ç¤ºå·¥å…·è°ƒç”¨è¿›åº¦
                config_dict["callbacks"] = [self.progress_callback]
                result = self.agent.invoke(input_data, config=config_dict)
                return result
        else:
            # ç›´æ¥ä½¿ç”¨LLM
            messages = input_data.get('messages', [])
            response = self.llm.invoke(messages)
            return {'messages': messages + [response]}
    
    @abstractmethod
    def run(self, state: dict) -> dict:
        """
        è¿è¡ŒAgentçš„ä¸»é€»è¾‘
        
        Args:
            state: å½“å‰çŠ¶æ€
        
        Returns:
            æ›´æ–°åçš„çŠ¶æ€
        """
        pass
